# ATenCog Subcomponents

This directory contains specialized agent definitions for ATenCog subsystems that implement the cognitive architecture's core capabilities.

## Agents

### ATenCog-Arch
**Neuro-Symbolic Architecture Agent** - Designs and orchestrates cognitive architectures that seamlessly integrate symbolic reasoning, probabilistic logic, neural networks, and evolutionary learning.

### ATenPLN
**Probabilistic Logic Networks Agent** - Implements uncertain reasoning using probabilistic logic, enabling inference with incomplete information and truth value propagation.

### ATenECAN
**Economic Attention Networks Agent** - Manages cognitive resources through economic principles, allocating attention and implementing forgetting mechanisms.

### ATenMOSES
**Meta-Optimizing Semantic Evolutionary Search Agent** - Implements program synthesis through evolutionary search, combining genetic algorithms with semantic knowledge.

### ATenNLU
**Natural Language Understanding Agent** - Bridges human language and machine cognition, processing text to extract structured knowledge and generating natural language.

### ATenVision
**Visual Perception Agent** - Processes visual input to extract structured knowledge, enabling grounded perception and scene understanding.

### ATenCog-Server
**Distributed Cognition Server Agent** - Orchestrates network-based cognitive services, enabling distributed reasoning and multi-agent coordination.

### ATenCog-Utils
**Cognitive Utilities Agent** - Provides essential tools including logging, debugging, visualization, and monitoring for cognitive system development.

### ATenCog-LLM
**Large Language Model Integration Agent** - Bridges pre-trained language models with symbolic cognitive architectures for enhanced reasoning and generation.

## Integration

These agents work together synergistically:
- **Architecture** orchestrates all components
- **PLN** provides reasoning, **ECAN** manages attention
- **MOSES** enables evolution, **ML/NN** enable learning
- **NLU** and **Vision** ground cognition in language and perception
- **Server** enables distribution, **Utils** supports development
- **LLM** leverages large-scale pre-trained models

Each agent is designed to operate independently while contributing to emergent cognitive capabilities when integrated.
